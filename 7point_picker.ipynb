{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e22133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def filter_sn_lightcurve_random(input_file):\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    t0 = None\n",
    "    header = []\n",
    "    obs_lines = []\n",
    "    footer = []\n",
    "\n",
    "    # 1. Parse the file\n",
    "    for line in lines:\n",
    "        if line.startswith('PEAKMJD:'):\n",
    "            t0 = float(line.split()[1])\n",
    "        \n",
    "        if line.startswith('OBS:'):\n",
    "            obs_lines.append(line)\n",
    "        elif line.startswith('END_PHOTOMETRY:'):\n",
    "            footer.append(line)\n",
    "        elif not line.startswith('TRIGGER:'): \n",
    "            header.append(line)\n",
    "\n",
    "    if t0 is None:\n",
    "        raise ValueError(\"Could not find PEAKMJD in the header.\")\n",
    "\n",
    "    # 2. Categorize observations into pools\n",
    "    pool_less_0 = []\n",
    "    pool_greater_10 = []\n",
    "    \n",
    "    for line in obs_lines:\n",
    "        t1 = float(line.split()[1])\n",
    "        delta = t1 - t0\n",
    "        \n",
    "        if delta < 0:\n",
    "            pool_less_0.append(line)\n",
    "        if delta > 10:\n",
    "            pool_greater_10.append(line)\n",
    "\n",
    "    # Make sure we have enough data to satisfy the bounds\n",
    "    if not pool_less_0:\n",
    "        raise ValueError(\"No observations found where t1 - t0 < 0.\")\n",
    "    if not pool_greater_10:\n",
    "        raise ValueError(\"No observations found where t1 - t0 > 10.\")\n",
    "\n",
    "    # 3. Randomly select the first two required rows\n",
    "    selected_less_0 = random.choice(pool_less_0)\n",
    "    selected_greater_10 = random.choice(pool_greater_10)\n",
    "    \n",
    "    # Keep track of what we've already picked so we don't duplicate\n",
    "    already_selected = {selected_less_0, selected_greater_10}\n",
    "\n",
    "    # 4. Create a pool for the remaining 5 rows, excluding the ones we just picked\n",
    "    pool_in_range = []\n",
    "    for line in obs_lines:\n",
    "        if line in already_selected:\n",
    "            continue  # Skip rows we already chose\n",
    "            \n",
    "        t1 = float(line.split()[1])\n",
    "        delta = t1 - t0\n",
    "        \n",
    "        if -15 <= delta <= 60:\n",
    "            pool_in_range.append(line)\n",
    "\n",
    "    if len(pool_in_range) < 5:\n",
    "        raise ValueError(f\"Not enough unique observations in the [-15, 60] range. Found {len(pool_in_range)}, need 5.\")\n",
    "\n",
    "    # Randomly sample exactly 5 unique rows from this range\n",
    "    selected_in_range = random.sample(pool_in_range, 5)\n",
    "\n",
    "    # 5. Combine and sort chronologically\n",
    "    final_selection = [selected_less_0, selected_greater_10] + selected_in_range\n",
    "    final_selection.sort(key=lambda x: float(x.split()[1]))\n",
    "    output_file = input_file\n",
    "    # 6. Write out the new file\n",
    "    with open(output_file, 'w') as f:\n",
    "        for line in header:\n",
    "            if line.startswith('NOBS:'):\n",
    "                f.write(f\"NOBS: {len(final_selection)}\\n\")\n",
    "            else:\n",
    "                f.write(line)\n",
    "        \n",
    "        for line in final_selection:\n",
    "            f.write(line)\n",
    "            \n",
    "        for line in footer:\n",
    "            f.write(line)\n",
    "\n",
    "\n",
    "\n",
    "def process_dat_files(directory_path, action_func):\n",
    "    \"\"\"\n",
    "    Finds every .dat file in the specified directory and applies \n",
    "    the action_func to it.\n",
    "    \"\"\"\n",
    "    # Create a Path object for the target directory\n",
    "    directory = Path(directory_path)\n",
    "    \n",
    "    # Check if the directory actually exists to avoid errors\n",
    "    if not directory.is_dir():\n",
    "        print(f\"Error: The directory '{directory_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Use .glob() to find all files ending in .dat\n",
    "    for file_path in directory.glob('*.dat'):\n",
    "        # Pass the file path to your custom action function\n",
    "        action_func(file_path)\n",
    "\n",
    "def extract_columns(filename, columns_to_extract):\n",
    "    headers = []\n",
    "    data = []\n",
    "    \n",
    "    # Read through the file line by line\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('VARNAMES:'):\n",
    "                # Get the column names, excluding the 'VARNAMES:' prefix\n",
    "                headers = line.strip().split()[1:]\n",
    "            elif line.startswith('SN:'):\n",
    "                # Get the data values, excluding the 'SN:' prefix\n",
    "                row = line.strip().split()[1:]\n",
    "                data.append(row)\n",
    "                \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    \n",
    "    # Convert string columns to numeric where possible\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "    \n",
    "    # Filter and return only the requested columns\n",
    "    return df[columns_to_extract]\n",
    "\n",
    "def run_exe_and_do_thing(omega_w):\n",
    "    \"\"\"\n",
    "    Launches an executable with arguments, waits for it to finish, \n",
    "    and then executes the next steps.\n",
    "    omega_w is a list of strings, e.g. [\"OMEGA_MATTER 0.3\", \"w 0.7\"]\n",
    "    \"\"\"\n",
    "    ## nomi dei files\n",
    "    nome_run = \"TEST1\" ## it is like this in the two input files, watch out for it!\n",
    "    nome_file_input = \"sim_SDSS_custom.input\"\n",
    "    nome_file_nml = \"snfit_SDSS_custom.nml\"\n",
    "    ## paths\n",
    "    snana_dir = \"~/SNANA\"\n",
    "    bin_dir = f\"{snana_dir}/SNDIR/bin\"\n",
    "    snlc_sim_path = f\"{bin_dir}/snlc_sim.exe\"\n",
    "    snlc_fit_path = f\"{bin_dir}/snlc_fit.exe\"\n",
    "    ## dir where we save snlc_sim.exe output .dat files \n",
    "    sim_dir_path = f\"{snana_dir}/SNROOT/SIM/{nome_run}\"\n",
    "    ## dir of the input files\n",
    "    snlc_sim_input = f\"{snana_dir}/custom_input_files/{nome_file_input}\"\n",
    "    snlc_fit_input = f\"{snana_dir}/custom_input_files/{nome_file_nml}\"\n",
    "\n",
    "    sim_command = [snlc_sim_path, snlc_sim_input] + omega_w\n",
    "    fit_command = [snlc_fit_path, snlc_fit_input]\n",
    "\n",
    "    result = subprocess.run(sim_command, capture_output=True, text=True, check=True)\n",
    "    \n",
    "    print(\"The .exe finished running successfully!\")\n",
    "    print(f\"Here is what the .exe output: {result.stdout}\")\n",
    "    print(\"cleaning\")\n",
    "    process_dat_files(sim_dir_path, filter_sn_lightcurve_random)\n",
    "    print(\"extracted 7 points from dat files\")\n",
    "    print(f\"Launching: {snlc_fit_path}\")\n",
    "    result = subprocess.run(fit_command, capture_output=True, text=True, check=True)\n",
    "    print(result.stdout)\n",
    "    print(\"fit done, output should be in where u launched this script\")\n",
    "    columns = ['zHEL', 'zHELERR','zCMB', 'zCMBERR','zHD','zHDERR', 'mB', 'x1', 'c']\n",
    "    fit_output = f\"{snana_dir}/scripts/{nome_run}.FITRES.TEXT\"\n",
    "    extract_columns(fit_output, columns)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5583cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_exe_and_do_thing([\"\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
